### Activity 4.2.3 - Solution

Open a new Jupyter notebook and name it `Activity_6.1.3.ipynb` and then open a new "code cell" and add the following: 

```python
import pandas as pd # import pandas (to read and work with csv files)
import numpy as np # import numpy (to create arrays)
import matplotlib.pyplot as plt # import matplotlib.pyplot (to create plots)
import seaborn as sns # import seaborn (to create plots)
import warnings # import warnings (to ignore warnings)
warnings.filterwarnings('ignore') # ignore warnings and do not show them
from sklearn.preprocessing import StandardScaler # import StandardScaler (to scale data)
```

1. Load again the data from file `data/customer_churn.csv`.

    <br>
    
    **Solution**

    <br>

    ```python
    data = pd.read_csv('data/customer_churn.csv') # read csv file and store in data
    ```

2. Get how many observations you have for every possible value of column `Churn`.

    <br>
    
    **Solution**

    <br>

    ```python
    data['Churn'].value_counts() # count unique values in 'Churn' column
    ```

3. Import the function [SMOTE](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html?highlight=smote#imblearn.over_sampling.SMOTE) and use it to balance the dataset ( use the same independent features used during the lesson ).

    <br>
    
    **Solution**

    <br>

    ```python
    from imblearn.over_sampling import SMOTE # import SMOTE (to oversample minority class)

    smote = SMOTE() # create SMOTE object and store in smote
    X = data[['tenure', 'SeniorCitizen','MonthlyCharges']] # store features in X (tenure, SeniorCitizen, MonthlyCharges)
    transformer = StandardScaler().fit(X) # create StandardScaler object and store in transformer (fit StandardScaler to X) 
    X_scaled = transformer.transform(X) # transform X using StandardScaler object and store in X_scaled
    y = data['Churn'] # store target in y (Churn)
    X_sm, y_sm = smote.fit_sample(X_scaled, y) # oversample minority class using SMOTE and store in X_sm and y_sm (X_scaled: scaled data, y: target)
    pd.DataFrame(y_sm).value_counts() # count unique values in y_sm and store in y_sm 
    ```

4. How many samples you have of each class after balancing?

    <br>
    
    **Solution**

    <br>

    5174 for both.

5. Now import the function [TomekLinks](https://imbalanced-learn.org/stable/references/generated/imblearn.under_sampling.TomekLinks.html?highlight=tomeklinks#imblearn.under_sampling.TomekLinks) and use it to balance the dataset (use the same independent features used during the lesson).

    <br>
    
    **Solution**

    <br>

    ```python
    from imblearn.under_sampling import TomekLinks # import TomekLinks (to undersample majority class)

    tl = TomekLinks('majority') # create TomekLinks object and store in tl (majority: undersample majority class)
    X = data[['tenure', 'SeniorCitizen','MonthlyCharges']] # store features in X (tenure, SeniorCitizen, MonthlyCharges)
    transformer = StandardScaler().fit(X) # create StandardScaler object and store in transformer (fit StandardScaler to X)
    X_scaled = transformer.transform(X) #  transform X using StandardScaler object and store in X_scaled and store in X_scaled
    y = data['Churn'] # store target in y (Churn)
    X_tl, y_tl = tl.fit_sample(X_scaled, y) # undersample majority class using TomekLinks and store in X_tl and y_tl (X_scaled: scaled data, y: target)
    pd.DataFrame(y_tl).value_counts() # count unique values in y_tl and store in y_tl
    ```


6. How many samples you have of each class after balancing? Discuss it. 

    <br>
    
    **Solution**

    <br>

    - No  -->   4694 
    - Yes -->   1869
    - Tomek's links doesn't fully balance your dataset. It only drops some samples of the majority class close to samples from the minority class.
