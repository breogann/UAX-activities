### Activity 4.1.1 - Solution

Open a new jupyter notebook. Name it as `Activity_4.1.1.ipynb` and do following:

* Load the contents of file data/test2.csv into a pandas dataframe

Solution

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

data = pd.read_csv("data/test2.csv",sep = ";") 
# Read a comma-separated values (csv) file into DataFrame.
# sep: Delimiter to use.
```

* Look for missing data using [isna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html?highlight=isna#pandas.DataFrame.isna)

Solution

```python
data.info() # prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.

data.isna().sum() # returns the number of missing values in each column.
```

* Fix the types using [astype()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html?highlight=astype#pandas.DataFrame.astype)

Solution 

```python
data = data.astype({'x1': 'float','x2': 'float','x3': 'float','x4': 'float', 'y':'float'})
# DataFrame.astype: Cast a pandas object to a specified dtype
    # dictionary: keys = column names, values = dtypes
```

* Create:
    - a new dataframe with columns ( `x1`, `x2`, `x3`, `x4 ) and name it `X`
    - a new dataframe with column `y` and name it `y`.


Solution

```python
X = data.drop(columns = ['y'], axis = 1) # drop y column from data and store in X
y = data[['y']] # store y column in y
```

* Use [sklearn single imputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) to impute the missing values of the `x` variables of the dataframe with the median and create a new dataframe from the resulting numpy array.

```python
from sklearn.impute import SimpleImputer # import SimpleImputer (to fill missing values in X data)

imp_median = SimpleImputer(strategy='median') # create imputer object (imputation strategy: 'median': replace missing values using the median along each column. Only with numeric data)
imp_median.fit(X) # fit imputer object to X  (X: dataframe)
X_imputed = imp_median.transform(X) # transform X using imputer object 

X_imputed = pd.DataFrame(X_imputed, columns = X.columns) # convert X_imputed to dataframe and store in X_imputed 
```

* Now drop any row of `X` and `y` where `y` has an NA.

Solution

```python
rows_to_drop = list(np.where( y.isna() == True )[0]) # create list of rows to drop from y and store in rows_to_drop
X.drop(rows_to_drop, axis = 0, inplace = True) # drop rows from X using rows_to_drop and store in X
y.drop(rows_to_drop, axis = 0, inplace = True) # drop rows from y using rows_to_drop and store in y 
```

* For every column of the new dataframe `X` plot in a single row ( from left to right ):
    - Histogram of each column

```python
fig, ax = plt.subplots(1,X.shape[1],figsize=(5*X.shape[1],5)) # create figure and axes for scatter plot of each feature in X 
for index, col in enumerate(X.columns): # iterating for each feature (index, col) using enumerate with columns names in X
   ax[index].hist(X[col],bins = 20) # create histogram of feature in X using bins = 20 and store in ax[index] 
   ax[index].set_xlabel(col) # set histogram name with col (column name)
fig.show() # show figure
```

* Import the [PowerTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html?highlight=powertransformer#sklearn.preprocessing.PowerTransformer) from sklearn and use it to transform all the columns from the dataframe `X`  and store the results into a new dataframe called `X_scaled`

Solution

```python
from sklearn.preprocessing import PowerTransformer # import PowerTransformer (PowerTransformer: transform data by applying a power function to each feature)

p_scaler = PowerTransformer() # create PowerTransformer object and store in p_scaler
p_scaler.fit(X) # fit PowerTransformer object to X (X: dataframe) and store in p_scaler
X_scaled = p_scaler.transform(X) # transform X using PowerTransformer object and store in X_scaled
X_scaled = pd.DataFrame(X_scaled, X.columns) # convert X_scaled to dataframe and store in X_scaled
```

* For every column of the `X_scaled` dataframe plot in a single row ( from left to right ):
    - Histogram of each column

Solution

```python
fig, ax = plt.subplots(1,X_scaled.shape[1],figsize=(5*X_scaled.shape[1],5)) # create figure and axes for scatter plot of each feature in X_scaled after scaling
for index, col in enumerate(X_scaled.columns): # itering for each feature (index, col) using enumerate with columns names in X_scaled
   ax[index].hist(X_scaled[col],bins = 20) # create histogram of feature in X_scaled using bins = 20 and store in ax[index]
   ax[index].set_xlabel(col) # set histogram name with col (column name)
fig.show() # show figure
```

* Do the transformed column values resemble a normal distribution?

Solution

```python
# More than before
```

* Save your scaler.

```python
import pickle # import pickle (to save and load objects) 

pickle.dump(p_scaler, open("p_scaler.pkl", 'wb')) # dump p_scaler object to file p_scaler.pkl (wb: write binary)
```




