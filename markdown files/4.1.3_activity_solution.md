### Activity 4.1.3 - Solution

Open a new jupyter notebook and name it as `Activity_4.1.3.ipynb`. 

* Open a new code cell in your notebook and install `plotly` library using:

```python
!pip install plotly
```

* Load the needed libraries for this activity:

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objects as go
import plotly.figure_factory as ff
%matplotlib inline
```

* Load the file `results.csv` used during the lesson into a pandas dataframe and inspect the first few lines

Solution

```python
results = pd.read_csv("data/results.csv")
results.head()
```

* Add a new columns called `residuals` with the diference between the real values and the predicted ones

Solution

```python
results['Residuals'] = results['y'] - results['y_pred']
```

* Drop the `Unnamed: 0` column

Solution

```python
results.drop(columns = ['Unnamed: 0'], axis = 1, inplace = True)
```

* Applying filters, create two new dataframes:
   - one containing only rows from `results` which belongs to the `train set`
   - one containing only rows frmo `results` which belongs to the `train set`

Solution

```python
train = results[ results['Set'] == "Train" ]
test  = results[ results['Set'] == "Test"  ]
```

* Complete the code accordingly and run it.

```python
# subplot setup
fig = make_subplots(rows=3, cols=2, 
                    subplot_titles=('Train set','Test set','Train set','Test set','Train set','Test set'),
                    vertical_spacing=0.10,
                    horizontal_spacing=0.10)
```

```python
# First plot
fig.add_trace(go.Scatter(x = , # Real values of the train set
                         y = , # Predicted values of the train set
                         mode='markers',
                         marker_color='rgb(16, 154, 246)')
                        ,row=1, col=1)

# Line of perfect fit
fig.add_shape(type="line",
              x0=0, 
              y0=0, 
              x1=70000, 
              y1=70000, row=1, col=1)

fig.update_xaxes(title_text="Real", row=1, col=1)
fig.update_yaxes(title_text="Predicted", row=1, col=1)

# Second plot
fig.add_trace(go.Scatter(x = , # Real values of the test set
                         y = , # Predicted values of the test set
                        mode='markers',
                        marker_color='rgb(246, 52, 16)')
                        ,row=1, col=2)

fig.update_xaxes(title_text="Real", row=1, col=2)
fig.update_yaxes(title_text="Predicted", row=1, col=2)

# Line of perfect fit
fig.add_shape(type="line",
              x0=0, 
              y0=0, 
              x1=70000, 
              y1=70000, row=1, col=2)

# Third plot
fig.add_trace(go.Scatter(x = , # Real values of the train set
                         y = , # Residuals from the train set
                         mode='markers',
                         marker_color='rgb(16, 154, 246)')
                        ,row=2, col=1)

fig.update_xaxes(title_text="Real", row=2, col=1)
fig.update_yaxes(title_text="Residual", row=2, col=1)

# Forth plot
fig.add_trace(go.Scatter(x = , # Real values of the test set
                         y = , # Residuals from the test set
                         mode='markers',
                         marker_color='rgb(246, 52, 16)')
                        ,row=2, col=2)

fig.update_xaxes(title_text="Real", row=2, col=2)
fig.update_yaxes(title_text="Residual", row=2, col=2)

# Fifth plot
fig.add_trace(go.Histogram(x = , # Residuals from the train set
                           marker_color='rgb(16, 154, 246)')
                        ,row=3, col=1)

fig.update_xaxes(title_text="Residuals", row=3, col=1)

# Last plot
fig.add_trace(go.Histogram(x = , # Residuals from the test set
                          marker_color='rgb(246, 52, 16)')
                        ,row=3, col=2)

fig.update_xaxes(title_text="Residuals", row=3, col=2)

fig.update_layout(title ='Error analysis', showlegend=False, height=1200)

fig.show()
```

* In the scatter plots, where the points should be located on the graph if the model were perfect? Do you see points quite far away from the line? Hover over them and identify some of them.

Solution

```
If the model is perfect, then the predicted values `y_pred` will match the real values `y`. Therefore `y_pred = y` which makes a perfect 
straight line with slope = 1 and intercept = 0.  
```

* Consider the  plots and answer the following questions:
   - are the residuals histograms symmetrical? if not what does it tell you about the model?

Solution

   ```
   Not exactly. 
   If the histogram has longer tails for positive values ( y - y_pred > 0 ), that will mean that on average the model is `underestimating` the real values: **underffiting**
   On the contrary, if the histogram has longer tails for negative values ( y - y_pred < 0 ), that will mean that on average the model is `overestimating` the real values. **overffiting**
   In this case, the model doesn't seem to fall in any of both extremes but it doesn't make a good job.
   ```

   - do they resemble a normal distribution?

Solution

   ```
   No, the normal distribution is not so spiked.
   ```
   - do they have long tails? why? 

Solution 

   ```
   Yes, because the model makes big mistakes.
   ```
   - in which range of values the model is making bigger mistakes? 

Solution

  ```
  Above 20k. Current features are not enough to explain the high values of the dependent feature.
  ```

